{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeba241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np  # Import numpy module and use 'np' as an alias\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044e0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da602707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_data):\n",
    "    \"\"\"\n",
    "    Read the JSON data and return relevant information for analysis.\n",
    "    \"\"\"\n",
    "    target = json_data['design_state_data']['target']['target']\n",
    "    regression_type = json_data['design_state_data']['target']['type']\n",
    "    features = json_data['design_state_data']['feature_handling']\n",
    "\n",
    "    return target, regression_type, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79374a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file and return it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71c4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_missing_imputation(df, feature_handling):\n",
    "    \"\"\"\n",
    "    Apply missing imputation to the DataFrame based on the feature handling configuration.\n",
    "    \"\"\"\n",
    "    for feature_name, feature_details in feature_handling.items():\n",
    "        if feature_details['is_selected']:\n",
    "            if feature_details['feature_details']['missing_values'] == 'Impute':\n",
    "                if feature_details['feature_details']['impute_with'] == 'Average of values':\n",
    "                    imputer = SimpleImputer(strategy='mean')\n",
    "                else:\n",
    "                    imputer = SimpleImputer(strategy='constant', fill_value=feature_details['feature_details']['impute_value'])\n",
    "                df[feature_name] = imputer.fit_transform(df[[feature_name]])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329ce80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_reduction(df, feature_reduction_method, reduction_params):\n",
    "    \"\"\"\n",
    "    Perform feature reduction based on the selected method.\n",
    "    \"\"\"\n",
    "    if feature_reduction_method == 'No Reduction':\n",
    "        pass\n",
    "    elif feature_reduction_method == 'Corr with Target':\n",
    "        # Implement feature reduction based on correlation with target\n",
    "        pass\n",
    "    elif feature_reduction_method == 'Tree-based':\n",
    "        # Implement tree-based feature reduction\n",
    "        pass\n",
    "    elif feature_reduction_method == 'PCA':\n",
    "        # Implement Principal Component Analysis (PCA) for feature reduction\n",
    "        pca = PCA(n_components=reduction_params.get('pca_components', 2))\n",
    "        df_reduced = pca.fit_transform(df)\n",
    "        return df_reduced\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature reduction method specified in the JSON.\")\n",
    "    return df\n",
    "\n",
    "def build_models(json_data):\n",
    "    \"\"\"\n",
    "    Build models based on the prediction_type specified in the JSON.\n",
    "    \"\"\"\n",
    "    prediction_type = json_data['design_state_data']['target']['prediction_type']\n",
    "    models = []\n",
    "\n",
    "    if prediction_type == 'Regression':\n",
    "        models.append(('RandomForestRegressor', RandomForestRegressor()))\n",
    "        models.append(('LinearRegression', LinearRegression()))\n",
    "    elif prediction_type == 'Classification':\n",
    "        models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "        models.append(('LogisticRegression', LogisticRegression()))\n",
    "        models.append(('SVC', SVC()))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid prediction_type specified in the JSON.\")\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acf493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_fit_predict(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Run model fit and prediction on each model.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904ec8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_metrics(y_true, y_pred, regression_type):\n",
    "    \"\"\"\n",
    "    Calculate model evaluation metrics based on regression_type.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    if regression_type == 'Regression':\n",
    "        # For Regression, use Mean Squared Error\n",
    "        metrics['MSE'] = mean_squared_error(y_true, y_pred)\n",
    "    elif regression_type == 'Classification':\n",
    "        # For Classification, use Accuracy and F1 Score\n",
    "        metrics['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "        metrics['F1 Score'] = f1_score(y_true, y_pred)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid regression_type specified in the JSON.\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1793715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_run_pipeline(json_data, csv_file_path):\n",
    "    \"\"\"\n",
    "    Parse the JSON and execute the machine learning pipeline.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the JSON data\n",
    "    target, regression_type, feature_handling = read_json(json_data)\n",
    "\n",
    "    # Step 2: Load the data from CSV\n",
    "    data = load_data(csv_file_path)\n",
    "\n",
    "    # Step 3: Apply missing imputation\n",
    "    data = apply_missing_imputation(data, feature_handling)\n",
    "\n",
    "    # Step 4: Feature Reduction\n",
    "    feature_reduction_method = json_data['design_state_data']['feature_reduction']['feature_reduction_method']\n",
    "    reduction_params = json_data['design_state_data']['feature_reduction'].get('reduction_params', {})\n",
    "    if feature_reduction_method != 'No Reduction':\n",
    "        data = perform_feature_reduction(data, feature_reduction_method, reduction_params)\n",
    "\n",
    "    # Step 5: Build models based on prediction type\n",
    "    models = build_models(json_data)\n",
    "\n",
    "    # Step 6: Prepare data for model training and evaluation\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "\n",
    "    # Step 7: Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 8: Create pipelines for each model with GridSearchCV for hyperparameter tuning\n",
    "    pipelines = []\n",
    "    for name, model in models:\n",
    "        pipeline_steps = []\n",
    "\n",
    "        # Feature Handling\n",
    "        for feature_name, feature_details in feature_handling.items():\n",
    "            if feature_details['is_selected']:\n",
    "                if feature_details['feature_details']['missing_values'] == 'Impute':\n",
    "                    if feature_details['feature_details']['impute_with'] == 'Average of values':\n",
    "                        imputer = SimpleImputer(strategy='mean')\n",
    "                    else:\n",
    "                        imputer = SimpleImputer(strategy='constant', fill_value=feature_details['feature_details']['impute_value'])\n",
    "                    pipeline_steps.append((feature_name + '_imputer', imputer))\n",
    "\n",
    "        # Feature Reduction\n",
    "        if feature_reduction_method == 'PCA':\n",
    "            n_components = reduction_params.get('pca_components', 2)\n",
    "            pipeline_steps.append(('pca', PCA(n_components=n_components)))\n",
    "        elif feature_reduction_method == 'Tree-based':\n",
    "            k_best = reduction_params.get('tree_k_best', 10)\n",
    "            pipeline_steps.append(('k_best', SelectKBest(k=k_best)))\n",
    "\n",
    "        # Model Building\n",
    "        pipeline_steps.append((name, model))\n",
    "\n",
    "        pipeline = Pipeline(pipeline_steps)\n",
    "        pipelines.append((name, pipeline))\n",
    "\n",
    "    # Step 9: Run the fit and predict on each model using GridSearchCV for hyperparameter tuning\n",
    "    for name, pipeline in pipelines:\n",
    "        grid_search = GridSearchCV(pipeline, param_grid={}, cv=5)  # Add param_grid for hyperparameter tuning\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred = grid_search.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
